{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "35d867db",
      "metadata": {
        "id": "35d867db"
      },
      "source": [
        "# Practice Assignment: Wine Classification (Starter Notebook)\n",
        "\n",
        "This notebook is a **starter template** with **TODOs**.  \n",
        "Complete each section and keep your answers in markdown cells.\n",
        "\n",
        "**Dataset:** `sklearn.datasets.load_wine`  \n",
        "**Goal:** Predict the wine class (3 classes) from 13 numeric features.\n",
        "\n",
        "---\n",
        "\n",
        "## Rules\n",
        "- Do **not** change the dataset.\n",
        "- Use a fixed random seed where requested.\n",
        "- Write short answers where asked.\n",
        "- Keep your code clean and reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1150a0d3",
      "metadata": {
        "id": "1150a0d3"
      },
      "outputs": [],
      "source": [
        "# TODO: Run this cell.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Models you may use (you will pick at least 3 in Part 4)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37928595",
      "metadata": {
        "id": "37928595"
      },
      "source": [
        "## Part 0 — Load the dataset\n",
        "\n",
        "**TODOs**\n",
        "1. Load the dataset using `load_wine()`\n",
        "2. Create a DataFrame `df` containing the features\n",
        "3. Create `X` (features) and `y` (target)\n",
        "4. Print:\n",
        "   - dataset shape\n",
        "   - feature names\n",
        "   - class distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0fb85c8",
      "metadata": {
        "id": "b0fb85c8",
        "outputId": "72286a30-fc3a-49d3-8c8d-10f913d74582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (178, 13)\n",
            "y shape: (178,)\n",
            "Features: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "Class counts: [59 71 48]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load wine dataset\n",
        "wine = load_wine()\n",
        "\n",
        "# TODO: Create DataFrame with features\n",
        "# Hint: wine.data is a (n_samples, n_features) numpy array\n",
        "# Hint: wine.feature_names is the list of column names\n",
        "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "\n",
        "# TODO: Create X and y\n",
        "X = df\n",
        "y = wine.target  # 0,1,2 correspond to classes\n",
        "\n",
        "# TODO: Print dataset shape\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", np.shape(y))\n",
        "\n",
        "# TODO: Print feature names\n",
        "print(\"Features:\", list(X.columns))\n",
        "\n",
        "# TODO: Print class distribution\n",
        "# Hint: np.bincount(y)\n",
        "print(\"Class counts:\", np.bincount(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LgDQ9fKbioa9",
        "outputId": "7a7a9736-9a54-4c95-fe44-1608e7b2197c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "id": "LgDQ9fKbioa9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38bfbb40-f418-401c-b5fc-b92954e4c6b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38bfbb40-f418-401c-b5fc-b92954e4c6b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38bfbb40-f418-401c-b5fc-b92954e4c6b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38bfbb40-f418-401c-b5fc-b92954e4c6b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3189c12b-b122-4359-94c6-4eca17a07d65\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3189c12b-b122-4359-94c6-4eca17a07d65')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3189c12b-b122-4359-94c6-4eca17a07d65 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 178,\n  \"fields\": [\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8118265380058577,\n        \"min\": 11.03,\n        \"max\": 14.83,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          11.62,\n          13.64,\n          13.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"malic_acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1171460976144627,\n        \"min\": 0.74,\n        \"max\": 5.8,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          1.21,\n          2.83,\n          1.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2743440090608148,\n        \"min\": 1.36,\n        \"max\": 3.23,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          2.31,\n          2.43,\n          2.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcalinity_of_ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3395637671735052,\n        \"min\": 10.6,\n        \"max\": 30.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          25.5,\n          28.5,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"magnesium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.282483515295668,\n        \"min\": 70.0,\n        \"max\": 162.0,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          126.0,\n          85.0,\n          162.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6258510488339891,\n        \"min\": 0.98,\n        \"max\": 3.88,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1.68,\n          2.11,\n          1.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flavanoids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9988586850169465,\n        \"min\": 0.34,\n        \"max\": 5.08,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          3.18,\n          2.5,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nonflavanoid_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12445334029667939,\n        \"min\": 0.13,\n        \"max\": 0.66,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.58,\n          0.41,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"proanthocyanins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5723588626747611,\n        \"min\": 0.41,\n        \"max\": 3.58,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.75,\n          1.77,\n          1.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.318285871822413,\n        \"min\": 1.28,\n        \"max\": 13.0,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          2.95,\n          3.3,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22857156582982338,\n        \"min\": 0.48,\n        \"max\": 1.71,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          1.22,\n          1.04,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"od280/od315_of_diluted_wines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7099904287650505,\n        \"min\": 1.27,\n        \"max\": 4.0,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          4.0,\n          1.82,\n          1.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"proline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314.9074742768489,\n        \"min\": 278.0,\n        \"max\": 1680.0,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          1375.0,\n          1270.0,\n          735.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see classes\n",
        "wine.target_names\n",
        "# TODO for Wednesday - FIND what these classes ACTUALLY MEAN\n"
      ],
      "metadata": {
        "id": "Xxr-H2mQi-ZN",
        "outputId": "e2efadf7-6271-479c-e2f4-35d428d8fa5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Xxr-H2mQi-ZN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtWxphkejJBb"
      },
      "id": "JtWxphkejJBb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e06502cf",
      "metadata": {
        "id": "e06502cf"
      },
      "source": [
        "## Part 1 — Quick EDA (minimal but required)\n",
        "\n",
        "**TODOs**\n",
        "1. Check for missing values\n",
        "2. Show basic descriptive statistics (mean, std, min, max)\n",
        "3. Plot at least **one** feature distribution grouped by class\n",
        "\n",
        "**Answer in markdown:**\n",
        "1. Are all features on similar numeric scales?\n",
        "2. Do any features appear clearly class-separating?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "722034a0",
      "metadata": {
        "id": "722034a0"
      },
      "outputs": [],
      "source": [
        "# TODO: Missing values check\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# TODO: Basic descriptive statistics\n",
        "# Hint: df.describe().T\n",
        "display(df.describe().T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "088e28a1",
      "metadata": {
        "id": "088e28a1"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot one feature distribution grouped by class\n",
        "# Pick ONE feature name from df.columns, e.g. 'alcohol' or 'color_intensity'\n",
        "feature = \"alcohol\"  # TODO: change if you want\n",
        "\n",
        "plt.figure()\n",
        "for cls in np.unique(y):\n",
        "    plt.hist(df.loc[y == cls, feature], alpha=0.5, bins=15, label=f\"class {cls}\")\n",
        "plt.xlabel(feature)\n",
        "plt.ylabel(\"count\")\n",
        "plt.title(f\"Distribution of {feature} by class\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15591c5",
      "metadata": {
        "id": "b15591c5"
      },
      "source": [
        "**Your answers (TODO):**\n",
        "\n",
        "1. Feature scales:  \n",
        "   - TODO\n",
        "\n",
        "2. Clear class separation:  \n",
        "   - TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6d6853",
      "metadata": {
        "id": "ac6d6853"
      },
      "source": [
        "## Part 2 — Train/test split\n",
        "\n",
        "Use an **80/20** split and `random_state=42`.\n",
        "\n",
        "**TODOs**\n",
        "- Create `X_train, X_test, y_train, y_test`\n",
        "- Print their shapes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29de1e21",
      "metadata": {
        "id": "29de1e21"
      },
      "outputs": [],
      "source": [
        "# TODO: Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test :\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_test :\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538a49d9",
      "metadata": {
        "id": "538a49d9"
      },
      "source": [
        "## Part 3 — Baseline model (Logistic Regression, **no scaling**)\n",
        "\n",
        "Train Logistic Regression without scaling and evaluate.\n",
        "\n",
        "**TODOs**\n",
        "1. Train Logistic Regression\n",
        "2. Predict on test set\n",
        "3. Report:\n",
        "   - Accuracy\n",
        "   - Confusion matrix\n",
        "   - Classification report\n",
        "\n",
        "**Reflection (markdown):**\n",
        "- Why might this baseline be suboptimal even if accuracy looks OK?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb30e292",
      "metadata": {
        "id": "bb30e292"
      },
      "outputs": [],
      "source": [
        "# TODO: Baseline logistic regression WITHOUT scaling\n",
        "# Hint: increase max_iter to avoid convergence warnings\n",
        "baseline_clf = LogisticRegression(max_iter=5000)\n",
        "\n",
        "baseline_clf.fit(X_train, y_train)\n",
        "y_pred_base = baseline_clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_base))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_base))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56cde7ab",
      "metadata": {
        "id": "56cde7ab"
      },
      "source": [
        "**Reflection (TODO):**  \n",
        "- TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d200d8",
      "metadata": {
        "id": "12d200d8"
      },
      "source": [
        "## Part 4 — Scaling + Logistic Regression (core lesson)\n",
        "\n",
        "Now apply `StandardScaler` and retrain Logistic Regression using a Pipeline.\n",
        "\n",
        "**TODOs**\n",
        "1. Create a pipeline: `StandardScaler()` -> `LogisticRegression()`\n",
        "2. Fit on training set\n",
        "3. Evaluate on test set\n",
        "4. Fill the comparison table (Accuracy and Macro F1)\n",
        "\n",
        "**Required written explanation (markdown):**\n",
        "- Explain *why* scaling changed (or did not change) the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29949d80",
      "metadata": {
        "id": "29949d80"
      },
      "outputs": [],
      "source": [
        "# TODO: Logistic regression WITH scaling using a pipeline\n",
        "scaled_lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=5000))\n",
        "])\n",
        "\n",
        "scaled_lr.fit(X_train, y_train)\n",
        "y_pred_scaled = scaled_lr.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_scaled))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_scaled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34edddd4",
      "metadata": {
        "id": "34edddd4"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute Macro F1 for baseline and scaled versions and fill the table below\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "acc_base = accuracy_score(y_test, y_pred_base)\n",
        "f1_base = f1_score(y_test, y_pred_base, average=\"macro\")\n",
        "\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "f1_scaled = f1_score(y_test, y_pred_scaled, average=\"macro\")\n",
        "\n",
        "acc_base, f1_base, acc_scaled, f1_scaled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "069ebd89",
      "metadata": {
        "id": "069ebd89"
      },
      "source": [
        "### Comparison table (fill in the numbers)\n",
        "\n",
        "| Metric | No Scaling (baseline LR) | With Scaling (LR) |\n",
        "|---|---:|---:|\n",
        "| Accuracy | TODO | TODO |\n",
        "| Macro F1 | TODO | TODO |\n",
        "\n",
        "**Explanation (TODO):**  \n",
        "- TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f429d966",
      "metadata": {
        "id": "f429d966"
      },
      "source": [
        "## Part 5 — Model comparison (train at least 3 models)\n",
        "\n",
        "Train and evaluate **at least 3** models from the list below:\n",
        "\n",
        "- KNN\n",
        "- SVM (linear or RBF)\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "\n",
        "**Rules**\n",
        "- Use the same train/test split.\n",
        "- Use scaling for models that need it (KNN, SVM, Logistic Regression).\n",
        "- Keep default hyperparameters (you may set `random_state` where available).\n",
        "\n",
        "**TODOs**\n",
        "1. Train your chosen models\n",
        "2. Compute accuracy + macro F1 for each\n",
        "3. Build a comparison table (DataFrame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6397a9",
      "metadata": {
        "id": "ed6397a9"
      },
      "outputs": [],
      "source": [
        "# TODO: Define candidate models\n",
        "# Tip: use Pipelines for models that need scaling\n",
        "models = {\n",
        "    \"KNN (scaled)\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", KNeighborsClassifier())]),\n",
        "    \"SVM RBF (scaled)\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC())]),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "# TODO: Choose at least 3 models to evaluate\n",
        "chosen_model_names = [\n",
        "    # \"KNN (scaled)\",\n",
        "    # \"SVM RBF (scaled)\",\n",
        "    # \"Decision Tree\",\n",
        "    # \"Random Forest\",\n",
        "]\n",
        "\n",
        "# TODO: Evaluate chosen models and store results\n",
        "results = []\n",
        "\n",
        "for name in chosen_model_names:\n",
        "    clf = models[name]\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy_score(y_test, preds),\n",
        "        \"macro_f1\": f1_score(y_test, preds, average=\"macro\"),\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"macro_f1\", ascending=False)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b72901",
      "metadata": {
        "id": "10b72901"
      },
      "source": [
        "**TODO:** Briefly comment (1–3 sentences) on which model performed best and any surprises.\n",
        "\n",
        "- TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93854aad",
      "metadata": {
        "id": "93854aad"
      },
      "source": [
        "## Part 6 — Overfitting check\n",
        "\n",
        "Pick your best-performing model from Part 5 and compare:\n",
        "\n",
        "- Training accuracy\n",
        "- Test accuracy\n",
        "\n",
        "**TODOs**\n",
        "1. Select the best model name from `results_df`\n",
        "2. Refit it on training set (if needed)\n",
        "3. Compute training and test accuracy\n",
        "4. Answer: Is there evidence of overfitting?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4daa9a",
      "metadata": {
        "id": "ca4daa9a"
      },
      "outputs": [],
      "source": [
        "# TODO: Pick best model from results_df\n",
        "# Example:\n",
        "# best_model_name = results_df.iloc[0][\"model\"]\n",
        "best_model_name = None  # TODO\n",
        "\n",
        "best_clf = models[best_model_name]\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "train_acc = accuracy_score(y_train, best_clf.predict(X_train))\n",
        "test_acc = accuracy_score(y_test, best_clf.predict(X_test))\n",
        "\n",
        "print(\"Best model:\", best_model_name)\n",
        "print(\"Training accuracy:\", train_acc)\n",
        "print(\"Test accuracy    :\", test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabd4cf0",
      "metadata": {
        "id": "dabd4cf0"
      },
      "source": [
        "**Overfitting judgment (TODO):**  \n",
        "- TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6243a364",
      "metadata": {
        "id": "6243a364"
      },
      "source": [
        "## Part 7 — Final reflection (required)\n",
        "\n",
        "Answer briefly:\n",
        "\n",
        "1. Which model performed best and why (in your view)?\n",
        "2. Which model would you **not** trust for this dataset?\n",
        "3. One common beginner mistake you made or almost made.\n",
        "\n",
        "**Your answers (TODO):**\n",
        "1. TODO  \n",
        "2. TODO  \n",
        "3. TODO  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ebb48e8",
      "metadata": {
        "id": "9ebb48e8"
      },
      "source": [
        "## Optional stretch goals (extra)\n",
        "\n",
        "Pick any ONE:\n",
        "\n",
        "- Add 5-fold cross-validation and compare to your test-set result\n",
        "- Make a PCA 2D plot to visualize class separation\n",
        "- Try GridSearchCV on KNN (`n_neighbors`) or SVM (`C`, `gamma`) *carefully* (small grid)\n",
        "\n",
        "*(Optional work should be clearly separated from the main assignment.)*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}