{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681c603f",
   "metadata": {},
   "source": [
    "# Session 2 — Working with Jupyter, Python, and ML Thinking\n",
    "\n",
    "**Focus of this notebook:** how ML work is done day-to-day in a Jupyter notebook (interactive exploration), not model training yet.\n",
    "\n",
    "**What this session is _not_:**\n",
    "- Not “production Python”\n",
    "- Not the full end-to-end ML workflow\n",
    "- Not a deep dive into libraries\n",
    "\n",
    "**What this session _is_:**\n",
    "- Understanding how code cells work\n",
    "- Understanding notebook state (powerful *and* dangerous)\n",
    "- Practicing the core habit: **inspect → clean → sanity-check**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc39a39",
   "metadata": {},
   "source": [
    "## 1) What is a Jupyter Notebook?\n",
    "\n",
    "A Jupyter notebook is a document made of **cells**:\n",
    "- **Markdown cells**: explanations, notes, instructions\n",
    "- **Code cells**: executable Python\n",
    "\n",
    "Key idea (many beginners miss this):\n",
    "\n",
    "> **Execution order is the order you run cells, not the order they appear on the page.**\n",
    "\n",
    "A notebook runs on a **kernel**: a live Python process that keeps variables in memory until you restart it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffaddc8",
   "metadata": {},
   "source": [
    "## 2) The “Hidden State” Problem (and Feature)\n",
    "\n",
    "A notebook remembers variables you created earlier. This is convenient for exploration, but it can also produce confusing bugs.\n",
    "\n",
    "We’ll intentionally demonstrate this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0449101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "x = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c935597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell after the one above\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b058d",
   "metadata": {},
   "source": [
    "### Now break it on purpose\n",
    "\n",
    "1. Click **Kernel → Restart Kernel** (or **Restart** in the UI)\n",
    "2. Run only the next cell (without re-running the earlier cell)\n",
    "\n",
    "You should get a `NameError`. That's the point.\n",
    "\n",
    "**Teaching point:** ML results can be wrong simply because your notebook state is not what you think it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After restarting the kernel, run ONLY this cell\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa0368",
   "metadata": {},
   "source": [
    "## 3) Python’s role in ML (practical view)\n",
    "\n",
    "In real ML work, Python is mostly used for:\n",
    "- loading data\n",
    "- cleaning and transforming it\n",
    "- running quick sanity checks\n",
    "- iterating fast\n",
    "\n",
    "It is much less about fancy syntax and much more about **small, correct transformations**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec62bb",
   "metadata": {},
   "source": [
    "## 4) A tiny “dataset” we can reason about\n",
    "\n",
    "We'll use a deliberately small dataset so you can see what's happening.\n",
    "\n",
    "Real datasets are larger, but the same thinking applies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [10, 12, None, 15, 1000, 14, None, 13]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d1eec",
   "metadata": {},
   "source": [
    "## 5) First ML habit: inspect before acting\n",
    "\n",
    "Before we “do something”:\n",
    "- How many values do we have?\n",
    "- Are there missing values?\n",
    "- Are there suspicious values?\n",
    "\n",
    "(Do not rush to “model training”.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3623eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8597c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at the raw data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c21f0c",
   "metadata": {},
   "source": [
    "## 6) Cleaning data (boring on purpose)\n",
    "\n",
    "Most ML work is *this*.\n",
    "\n",
    "We'll remove missing values (`None`). There are other approaches (imputation), but this is enough to demonstrate the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2168ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = [x for x in data if x is not None]\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611263d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4c13d",
   "metadata": {},
   "source": [
    "## 7) Sanity-checking with a simple plot\n",
    "\n",
    "We are not “making charts”. We are **asking a question**:\n",
    "\n",
    "> “Does anything look obviously wrong?”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cleaned)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db60e7",
   "metadata": {},
   "source": [
    "### Interpretation questions (write your answers)\n",
    "\n",
    "- Does the scale look reasonable?\n",
    "- Is there an outlier?\n",
    "- What would a model do with a value like `1000`?\n",
    "- If you remove it, what assumption are you making?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231d335",
   "metadata": {},
   "source": [
    "## 8) Notebooks vs. “real world” code\n",
    "\n",
    "Notebooks are excellent for:\n",
    "- exploration\n",
    "- learning\n",
    "- prototyping\n",
    "- debugging assumptions\n",
    "\n",
    "Notebooks are risky for:\n",
    "- production pipelines\n",
    "- reproducibility without discipline\n",
    "- collaboration (diffs can be messy)\n",
    "\n",
    "This is why ML workflows often start in notebooks and later move to scripts/pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc2109",
   "metadata": {},
   "source": [
    "## 9) How today maps to the ML process\n",
    "\n",
    "| What we did | ML meaning |\n",
    "|---|---|\n",
    "| Created a small dataset | Data acquisition (toy example) |\n",
    "| Inspected length and values | Early data understanding |\n",
    "| Cleaned missing values | Data preparation |\n",
    "| Plotted the cleaned data | Exploratory sanity check |\n",
    "| Experienced `NameError` after restart | Reproducibility / hidden-state risk |\n",
    "\n",
    "You are building the habit: **inspect → transform → sanity-check**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9515d",
   "metadata": {},
   "source": [
    "## 10) What’s next (next session)\n",
    "\n",
    "Next session we move from exploration to a **repeatable workflow**:\n",
    "- train/test split\n",
    "- evaluation metrics (and why accuracy can mislead)\n",
    "- avoiding “accidental cheating” (data leakage)\n",
    "- first end-to-end model training (carefully)\n",
    "\n",
    "> Next time, we stop trusting ourselves and start validating.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
