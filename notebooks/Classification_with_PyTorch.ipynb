{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch classification\n",
        "\n",
        "Below is a clean, end‑to‑end PyTorch example you can run in Google Colab to train a strong CNN on Fashion‑MNIST. It includes data loading, on‑the‑fly augmentation, a compact CNN with batch norm and dropout, mixed precision, a modern One‑Cycle learning rate schedule, and automatic checkpointing.\n",
        "\n",
        "Tip: In Colab, set Runtime → Change runtime type → Hardware accelerator → GPU before running.\n",
        "\n",
        "## Official Page\n",
        "\n",
        "https://pytorch.org/"
      ],
      "metadata": {
        "id": "AP3OaHR6-N0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic4ovJYD96IS"
      },
      "outputs": [],
      "source": [
        "# If running in Google Colab, this cell is enough to train/evaluate Fashion-MNIST.\n",
        "# It uses a compact CNN, mixed precision, and OneCycleLR for fast convergence.\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Reproducibility and device\n",
        "# ---------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch: {torch.__version__}, TorchVision: {torchvision.__version__}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(torch.cuda.get_device_name())\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Data: transforms, dataset, loaders\n",
        "# ---------------------------\n",
        "# Fashion-MNIST grayscale stats (approx)\n",
        "MEAN, STD = 0.2861, 0.3530\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomCrop(28, padding=2, padding_mode=\"reflect\"),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((MEAN,), (STD,)),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((MEAN,), (STD,)),\n",
        "])\n",
        "\n",
        "data_root = \"./data\"\n",
        "\n",
        "train_set = FashionMNIST(root=data_root, train=True, download=True, transform=train_tfms)\n",
        "test_set  = FashionMNIST(root=data_root, train=False, download=True, transform=test_tfms)\n",
        "\n",
        "# Validation split from train\n",
        "val_ratio = 0.1667  # ~10k validation out of 60k\n",
        "val_size = int(len(train_set) * val_ratio)\n",
        "train_size = len(train_set) - val_size\n",
        "train_set, val_set = torch.utils.data.random_split(train_set, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = min(4, os.cpu_count() or 0)\n",
        "pin_memory = device.type == \"cuda\"\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory, persistent_workers=num_workers > 0)\n",
        "val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory, persistent_workers=num_workers > 0)\n",
        "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory, persistent_workers=num_workers > 0)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Model: compact, accurate CNN\n",
        "# ---------------------------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.drop = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, base=32, p_drop=0.25):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, base, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(base),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.block1 = ConvBlock(base, base, dropout=p_drop)\n",
        "        self.pool1  = nn.MaxPool2d(2)  # 28 -> 14\n",
        "        self.block2 = ConvBlock(base, base*2, dropout=p_drop)  # increase channels\n",
        "        self.pool2  = nn.MaxPool2d(2)  # 14 -> 7\n",
        "        self.block3 = ConvBlock(base*2, base*4, dropout=p_drop)\n",
        "        self.head   = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),  # global average pool to (C,1,1)\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base*4, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
        "                if m.bias is not None:\n",
        "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
        "                    bound = 1 / math.sqrt(fan_in)\n",
        "                    nn.init.uniform_(m.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block1(x); x = self.pool1(x)\n",
        "        x = self.block2(x); x = self.pool2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "model = FashionCNN().to(device)\n",
        "\n",
        "# Optional: torch.compile for speed (PyTorch 2.x)\n",
        "try:\n",
        "    model = torch.compile(model)  # if not supported, this will raise and be ignored\n",
        "    print(\"Model compiled with torch.compile\")\n",
        "except Exception as e:\n",
        "    print(f\"torch.compile unavailable or failed: {e}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Optimizer, loss, scheduler, AMP\n",
        "# ---------------------------\n",
        "epochs = 15\n",
        "lr_max = 3e-3\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=lr_max, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=lr_max,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    pct_start=0.25,\n",
        "    div_factor=10.0,\n",
        "    final_div_factor=10.0,\n",
        "    anneal_strategy=\"cos\",\n",
        ")\n",
        "\n",
        "use_amp = device.type == \"cuda\"\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Training / evaluation loops\n",
        "# ---------------------------\n",
        "def accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    total_n = 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "        bs = images.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc += accuracy(logits, labels) * bs\n",
        "        total_n += bs\n",
        "    return total_loss / total_n, total_acc / total_n\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    total_n = 0\n",
        "\n",
        "    pbar = tqdm(loader, leave=False)\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        bs = images.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc += accuracy(logits, labels) * bs\n",
        "        total_n += bs\n",
        "\n",
        "        pbar.set_description(f\"Train loss {total_loss/total_n:.4f} | acc {total_acc/total_n:.4f}\")\n",
        "\n",
        "    return total_loss / total_n, total_acc / total_n\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 5) Train with checkpointing and early stop (by patience on val loss)\n",
        "# ---------------------------\n",
        "best_val_loss = float(\"inf\")\n",
        "best_val_acc = 0.0\n",
        "patience = 5\n",
        "patience_ctr = 0\n",
        "ckpt_path = \"best_fashion_mnist.pt\"\n",
        "\n",
        "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    t0 = time.time()\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
        "    val_loss, val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    improved = val_loss < best_val_loss - 1e-4\n",
        "    if improved:\n",
        "        best_val_loss = val_loss\n",
        "        best_val_acc = val_acc\n",
        "        patience_ctr = 0\n",
        "        torch.save({\"model\": model.state_dict()}, ckpt_path)\n",
        "    else:\n",
        "        patience_ctr += 1\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(f\"Epoch {epoch:02d}/{epochs} | {dt:.1f}s  \"\n",
        "          f\"train_loss {train_loss:.4f} acc {train_acc:.4f}  \"\n",
        "          f\"val_loss {val_loss:.4f} acc {val_acc:.4f}  \"\n",
        "          f\"{'(saved)' if improved else ''}\")\n",
        "\n",
        "    if patience_ctr >= patience:\n",
        "        print(\"Early stopping: no improvement on val loss.\")\n",
        "        break\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Load best model and evaluate on test set\n",
        "# ---------------------------\n",
        "if os.path.exists(ckpt_path):\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(state[\"model\"])\n",
        "test_loss, test_acc = evaluate(model, test_loader)\n",
        "print(f\"Test  loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "Dm9h-KQr-wC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "id": "VOlO_hPxCCH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's download the model\n",
        "from google.colab import files\n",
        "files.download('best_fashion_mnist.pt')"
      ],
      "metadata": {
        "id": "xy32wxdsCTpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting answers for particular item"
      ],
      "metadata": {
        "id": "MZd9hCrSEE-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Get the first batch from the test loader\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# Get the first image and its true label\n",
        "first_image = images[0]\n",
        "true_label = labels[0].item()\n",
        "\n",
        "# Move image to device and add a batch dimension for prediction\n",
        "input_image = first_image.unsqueeze(0).to(device)\n",
        "\n",
        "# Make prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "        output = model(input_image)\n",
        "    # we obtain all probabilities for this item\n",
        "    probabilities = F.softmax(output, dim=1)\n",
        "    # we find highest probability and its index\n",
        "    predicted_prob, predicted_idx = torch.max(probabilities, 1)\n",
        "predicted_label = predicted_idx.item()\n",
        "\n",
        "# Unnormalize and display the image\n",
        "# For visualization, we reverse the normalization\n",
        "mean = np.array(MEAN)\n",
        "std = np.array(STD)\n",
        "\n",
        "img_display = first_image.cpu().numpy().transpose((1, 2, 0)) # C, H, W -> H, W, C\n",
        "img_display = img_display * std + mean # Unnormalize\n",
        "img_display = np.clip(img_display, 0, 1)\n",
        "\n",
        "plt.imshow(img_display.squeeze(), cmap='gray')\n",
        "plt.title(f\"True: {class_names[true_label]}, Predicted: {class_names[predicted_label]} ({predicted_prob.item():.2f})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Actual label: {class_names[true_label]}\")\n",
        "print(f\"Predicted label: {class_names[predicted_label]}\")\n",
        "print(f\"Prediction confidence: {predicted_prob.item():.4f}\")"
      ],
      "metadata": {
        "id": "hjfeoF7fDDnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's show all probabilities\n",
        "probabilities\n"
      ],
      "metadata": {
        "id": "coJL39a5C87D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}